{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to POD Project Overview POD (Synonymous for Python Object Detection) project usefull to determin and detect objects in Images , Videos and also WebCam like cat, dog, car and etc! Basically, this project is used as an api for projects used to detect objects. POD Project have two part : UserInterface Core Core can be used without UI in your project. The UI is used to make it look more beautiful and have a better feeling when working in this project! In UI we used flet framework to have a fantasy UI! POD used ONNX Models and YOLOv7 algorithm for train, object localization and object detection What is ONNX Models ? ONNX is an intermediary machine learning framework used to convert between different machine learning frameworks. So let's say you're in TensorFlow, and you want to get to TensorRT, or you're in PyTorch, and you want to get to TFLite, or some other machine learning framework. ONNX is a good intermediary to use to convert your model as you're going through these different machine learning frameworks. ONNX has worked really hard to basically implement all kinds of different neural network functions and different functionalities in these machine learning models, so we can support this cross functionality to have baseline, common framework to convert into. There are several ways in which you can obtain a model in the ONNX format, including: ONNX Model Zoo: Contains several pre-trained ONNX models for different types of tasks. Read More What is YOLOv7 algorithm ? YOLO (\u201cYou Only Look Once\u201d) is an effective real-time object recognition algorithm, first described in the seminal 2015 paper by Joseph Redmon et al. Since the release of YOLOv1 in 2015, the algorithm has gained immense popularity among the computer vision community. Furthermore, the updated version of the model YOLOv2, YOLOv3, YOLOv4, YOLOv5, YOLOv6, and very much recently, YOLOv7 has been released so far. Note that YOLOv5 has been one of the most successful and commonly used versions of the YOLO series. So the same team creating the updated version is a reason to consider learning it. Yolov7 is a real-time object detector currently revolutionizing the computer vision industry with its incredible features. The official YOLOv7 provides unbelievable speed and accuracy compared to its previous versions. Yolov7 weights are trained using Microsoft\u2019s COCO dataset, and no pre-trained weights are used. Read More Most commonly frameworks and other tools that used in this project is : Numpy: 1.23.5 opencv-python: 4.6.0.66 Sympy: 1.11.1 Onnxruntime: 1.13.1 Pillow: 9.3.0 How to install and use ? To see how to install and use, refer to the relevant sections. Project Directory |\u2014 assets/ # Outputs will saved in this place |\u2014\u2014\u2014\u2014\u2014 out_images/ |\u2014\u2014\u2014\u2014\u2014 out_videos/ |\u2014 models/ # models will be saved at this directory |\u2014\u2014\u2014\u2014\u2014 yourmodel.onnx |\u2014 mkdocs.yml # The configuration file. |\u2014 docs/ |\u2014\u2014\u2014\u2014 index.md # The documentation homepage. |\u2014\u2014\u2014\u2014 about.md # The documentaion about page. |\u2014\u2014\u2014\u2014 how-use.md # The documentaion user guide page. |\u2014\u2014\u2014\u2014 installation.md # The documentaion install guide page. |\u2014 Samples/ |\u2014\u2014\u2014\u2014\u2014 Images/ |\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014 ... # Some Images saved by default. |\u2014 Core |\u2014\u2014\u2014\u2014\u2014 yolov7/ # Pre-trained models by Yolov7 algorithm |\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014 __init__.py |\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014 utils.py |\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014 YOLOv7.py |\u2014\u2014\u2014\u2014\u2014 AiCore.py |\u2014\u2014\u2014\u2014\u2014 __init__.py |\u2014 UI |\u2014\u2014\u2014\u2014\u2014 appUI.py # UserInterface |\u2014 requirements.txt # requirement packages","title":"Home"},{"location":"#welcome-to-pod-project","text":"","title":"Welcome to POD Project"},{"location":"#overview","text":"POD (Synonymous for Python Object Detection) project usefull to determin and detect objects in Images , Videos and also WebCam like cat, dog, car and etc! Basically, this project is used as an api for projects used to detect objects. POD Project have two part : UserInterface Core Core can be used without UI in your project. The UI is used to make it look more beautiful and have a better feeling when working in this project! In UI we used flet framework to have a fantasy UI! POD used ONNX Models and YOLOv7 algorithm for train, object localization and object detection","title":"Overview"},{"location":"#what-is-onnx-models","text":"ONNX is an intermediary machine learning framework used to convert between different machine learning frameworks. So let's say you're in TensorFlow, and you want to get to TensorRT, or you're in PyTorch, and you want to get to TFLite, or some other machine learning framework. ONNX is a good intermediary to use to convert your model as you're going through these different machine learning frameworks. ONNX has worked really hard to basically implement all kinds of different neural network functions and different functionalities in these machine learning models, so we can support this cross functionality to have baseline, common framework to convert into. There are several ways in which you can obtain a model in the ONNX format, including: ONNX Model Zoo: Contains several pre-trained ONNX models for different types of tasks. Read More","title":"What is ONNX Models ?"},{"location":"#what-is-yolov7-algorithm","text":"YOLO (\u201cYou Only Look Once\u201d) is an effective real-time object recognition algorithm, first described in the seminal 2015 paper by Joseph Redmon et al. Since the release of YOLOv1 in 2015, the algorithm has gained immense popularity among the computer vision community. Furthermore, the updated version of the model YOLOv2, YOLOv3, YOLOv4, YOLOv5, YOLOv6, and very much recently, YOLOv7 has been released so far. Note that YOLOv5 has been one of the most successful and commonly used versions of the YOLO series. So the same team creating the updated version is a reason to consider learning it. Yolov7 is a real-time object detector currently revolutionizing the computer vision industry with its incredible features. The official YOLOv7 provides unbelievable speed and accuracy compared to its previous versions. Yolov7 weights are trained using Microsoft\u2019s COCO dataset, and no pre-trained weights are used. Read More","title":"What is YOLOv7 algorithm ?"},{"location":"#most-commonly-frameworks-and-other-tools-that-used-in-this-project-is","text":"Numpy: 1.23.5 opencv-python: 4.6.0.66 Sympy: 1.11.1 Onnxruntime: 1.13.1 Pillow: 9.3.0","title":"Most commonly frameworks and other tools that used in this project is :"},{"location":"#how-to-install-and-use","text":"To see how to install and use, refer to the relevant sections.","title":"How to install and use ?"},{"location":"#project-directory","text":"|\u2014 assets/ # Outputs will saved in this place |\u2014\u2014\u2014\u2014\u2014 out_images/ |\u2014\u2014\u2014\u2014\u2014 out_videos/ |\u2014 models/ # models will be saved at this directory |\u2014\u2014\u2014\u2014\u2014 yourmodel.onnx |\u2014 mkdocs.yml # The configuration file. |\u2014 docs/ |\u2014\u2014\u2014\u2014 index.md # The documentation homepage. |\u2014\u2014\u2014\u2014 about.md # The documentaion about page. |\u2014\u2014\u2014\u2014 how-use.md # The documentaion user guide page. |\u2014\u2014\u2014\u2014 installation.md # The documentaion install guide page. |\u2014 Samples/ |\u2014\u2014\u2014\u2014\u2014 Images/ |\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014 ... # Some Images saved by default. |\u2014 Core |\u2014\u2014\u2014\u2014\u2014 yolov7/ # Pre-trained models by Yolov7 algorithm |\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014 __init__.py |\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014 utils.py |\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014 YOLOv7.py |\u2014\u2014\u2014\u2014\u2014 AiCore.py |\u2014\u2014\u2014\u2014\u2014 __init__.py |\u2014 UI |\u2014\u2014\u2014\u2014\u2014 appUI.py # UserInterface |\u2014 requirements.txt # requirement packages","title":"Project Directory"},{"location":"about/","text":"Contact Dianae ipse loca dicere si aries viaeque Lorem markdownum ab obsceno liceat modo, vero capillis illo, quies, per. Corpora inque simul, usa Eurydicenque mihi precesque nocturnae quod moventem dextraque placida Herculis patrem amplectitur illa atque clamata, tellus. Subiecit quamvis remotis ostendere domos: leoni sunt vixi circumfert capax, ingratum viget est adest ut relatus est possem. Quod velamina victa novissima: patrio similisque reducet raucis deserta Tarpeias. Navifragumque moriere petebat diffusum, venae crate , decimum, in. if (task_igp_disk) { external_dcim = fatOnline; } if (keyPlay <= hfs_nvram_ieee(bug + 1, rom, matrix)) { software_atm += -3; wikiTopologyServices(basic_lion_directory); } infotainment.fileDialSystem += computer_cookie_vlog; nvramRtf.postscript_virtualization = control + daw_zip; app_box += 907610 * backlink_dual_smb(tokenIndex, duplexSmsBounce); Mitte vultu Achilli, que huc at humo gaude anhelatos hasta edocuit cernere nihil marmore amplectitur perque: quo ad. Est est vivitur orandus socios, paene, Phoebi tradiderat Mnemonides; ut in dare solverat , spoliataque. Est expositum amplexa: erat velari: possum: donec caede, et fusile primum aurata. Vestigia sim mentes liquido pudicam faciat; cepit habet magico membra, ubi. Illud tempore hoc quamvis sorore, campis consumpserat Iacchus clam habet deum lumen. Tegit accipiunt satus Pronumque et harenam tandem, et relinquo dictaque fuisset potest in terrestribus et Troiae recenti. Tibi coronis nobis iubeas perspice naturalique causa morte est illa fit; aperite. Ignipedum temperat Thermodonque hic pressos hic aegro adsimulat nostri aequor, mihi, cum. Cepit eo parentis nec recepta ferat; pio ter Bacchus umor rerum spargit. Populusque nec tergo Quod dispar cornu aether corporis et latet Pectusque titulos Iuppiter Quid ter laevae facit tenebat manet Et atra omne forent dolori caelestia honore Fuit praemia timuit conplevit pecoris flecti relinquam causatur meorum deflevere sacras Iulius dicta, cetera. Levis sole, repono e aspera furtim ubere gelido, quoque. Suae accessit limine primum, non ignotos optata in est enim fame, recumbere. Sustinet sacra capessamus quoque non terram falsa loquax audita floribus Non debueram damnatus quas virilem nisi moenia . Deos insanaque et montis proles arcus nomen nostrum Byblis, sociis. Quo congrediturque nomen Ignibus et Aenea mali digna dextra incepto quoque recipit tumidus Asterien; ore platanum hirsutaque veneni, permanet . Oscula nympha Nasamoniaci fine variusque sono currant? Quod fallacis ; ferendo vero alieno: et et non nati adest florentia haec flavae parte, vota inquit quis! Quasque nunc feta tristis tu mando, solvit progeniem; animo crepitante mores. Pharetrae Dindymaque vidit promissaque illam iaculo viscera exhibita recenti nec mox nitido luctantia tristia potentia accipe te mota Meleagros. memoryEthernet = file; serial += sdram_bare_disk; encoding.sound += responsive_skin_modem.reader(xp(pipelineDock(t_folder, drive_printer_p), pageWebWorm.gamma(cardPhp))); bloatware_drive_root += disk_bookmark_technology.outputVdsl( ddrLag.frameEngine(traceroute_fiber) * smmRom, fiber_dimm_formula + 4, 33); Pietas ignibus; qui aliquo loca, loci reor corpora et nurus monstraverat Iunonia per. De odores levavit . Non duros, brevi dederat me oreada, vitae, loci validi Midan sororia voles saltus ipse!","title":"About"},{"location":"about/#contact","text":"","title":"Contact"},{"location":"about/#dianae-ipse-loca-dicere-si-aries-viaeque","text":"Lorem markdownum ab obsceno liceat modo, vero capillis illo, quies, per. Corpora inque simul, usa Eurydicenque mihi precesque nocturnae quod moventem dextraque placida Herculis patrem amplectitur illa atque clamata, tellus. Subiecit quamvis remotis ostendere domos: leoni sunt vixi circumfert capax, ingratum viget est adest ut relatus est possem. Quod velamina victa novissima: patrio similisque reducet raucis deserta Tarpeias. Navifragumque moriere petebat diffusum, venae crate , decimum, in. if (task_igp_disk) { external_dcim = fatOnline; } if (keyPlay <= hfs_nvram_ieee(bug + 1, rom, matrix)) { software_atm += -3; wikiTopologyServices(basic_lion_directory); } infotainment.fileDialSystem += computer_cookie_vlog; nvramRtf.postscript_virtualization = control + daw_zip; app_box += 907610 * backlink_dual_smb(tokenIndex, duplexSmsBounce); Mitte vultu Achilli, que huc at humo gaude anhelatos hasta edocuit cernere nihil marmore amplectitur perque: quo ad. Est est vivitur orandus socios, paene, Phoebi tradiderat Mnemonides; ut in dare solverat , spoliataque. Est expositum amplexa: erat velari: possum: donec caede, et fusile primum aurata. Vestigia sim mentes liquido pudicam faciat; cepit habet magico membra, ubi. Illud tempore hoc quamvis sorore, campis consumpserat Iacchus clam habet deum lumen.","title":"Dianae ipse loca dicere si aries viaeque"},{"location":"about/#tegit-accipiunt-satus","text":"Pronumque et harenam tandem, et relinquo dictaque fuisset potest in terrestribus et Troiae recenti. Tibi coronis nobis iubeas perspice naturalique causa morte est illa fit; aperite. Ignipedum temperat Thermodonque hic pressos hic aegro adsimulat nostri aequor, mihi, cum. Cepit eo parentis nec recepta ferat; pio ter Bacchus umor rerum spargit. Populusque nec tergo Quod dispar cornu aether corporis et latet Pectusque titulos Iuppiter Quid ter laevae facit tenebat manet Et atra omne forent dolori caelestia honore Fuit praemia timuit conplevit pecoris flecti relinquam causatur meorum deflevere sacras Iulius dicta, cetera. Levis sole, repono e aspera furtim ubere gelido, quoque. Suae accessit limine primum, non ignotos optata in est enim fame, recumbere. Sustinet sacra capessamus quoque non terram falsa loquax audita floribus Non debueram damnatus quas virilem nisi moenia . Deos insanaque et montis proles arcus nomen nostrum Byblis, sociis.","title":"Tegit accipiunt satus"},{"location":"about/#quo-congrediturque-nomen","text":"Ignibus et Aenea mali digna dextra incepto quoque recipit tumidus Asterien; ore platanum hirsutaque veneni, permanet . Oscula nympha Nasamoniaci fine variusque sono currant? Quod fallacis ; ferendo vero alieno: et et non nati adest florentia haec flavae parte, vota inquit quis! Quasque nunc feta tristis tu mando, solvit progeniem; animo crepitante mores. Pharetrae Dindymaque vidit promissaque illam iaculo viscera exhibita recenti nec mox nitido luctantia tristia potentia accipe te mota Meleagros. memoryEthernet = file; serial += sdram_bare_disk; encoding.sound += responsive_skin_modem.reader(xp(pipelineDock(t_folder, drive_printer_p), pageWebWorm.gamma(cardPhp))); bloatware_drive_root += disk_bookmark_technology.outputVdsl( ddrLag.frameEngine(traceroute_fiber) * smmRom, fiber_dimm_formula + 4, 33); Pietas ignibus; qui aliquo loca, loci reor corpora et nurus monstraverat Iunonia per. De odores levavit . Non duros, brevi dederat me oreada, vitae, loci validi Midan sororia voles saltus ipse!","title":"Quo congrediturque nomen"},{"location":"how-use/","text":"The following steps guide you in using POD: Step 1: import package To use pod project features just import ai_core package : from pod_project import ai_core Step 2: To image detection To use image detection, just do this: ai_core.image_detection(from_path=\"local_path\", from_url=\"url_path\") In above code, we have two parameters : from_path: If you have image already in your local system, so you can use this. from_url: If you want use a url in network, so you can use this. For example : from_path: ai_core.image_detection(from_path=\"C:\\ImagePath\\example.jpg\") from_url: ai_core.image_detection(from_url=\"https://cdn.britannica.com/88/150788-050-77F67105/Children-corn-Terekeka-South-Sudan.jpg\") Step 3: Install requiremenet packages To install requirement packages, just run this command in your terminal: Linux: python3 -m pip install -r requirements.txt Windows: python -m pip install -r requirements.txt","title":"How to use"},{"location":"how-use/#step-1-import-package","text":"To use pod project features just import ai_core package : from pod_project import ai_core","title":"Step 1: import package"},{"location":"how-use/#step-2-to-image-detection","text":"To use image detection, just do this: ai_core.image_detection(from_path=\"local_path\", from_url=\"url_path\") In above code, we have two parameters : from_path: If you have image already in your local system, so you can use this. from_url: If you want use a url in network, so you can use this.","title":"Step 2: To image detection"},{"location":"how-use/#for-example","text":"from_path: ai_core.image_detection(from_path=\"C:\\ImagePath\\example.jpg\") from_url: ai_core.image_detection(from_url=\"https://cdn.britannica.com/88/150788-050-77F67105/Children-corn-Terekeka-South-Sudan.jpg\")","title":"For example :"},{"location":"how-use/#step-3-install-requiremenet-packages","text":"To install requirement packages, just run this command in your terminal: Linux: python3 -m pip install -r requirements.txt Windows: python -m pip install -r requirements.txt","title":"Step 3: Install requiremenet packages"},{"location":"installation/","text":"The following steps guide you in installing POD: Step 1: Create a virtual environment First of all you need create a virtual environment to install packages in one place! For initialize a virtual environment run this command in your terminal: Linux: python3 -m venv venv Windows: python -m venv venv Note: Second venv is my choice, So you can choose another name. Step 2: Active virtual environment To active virtual environment, run this command in your terminal: Linux: source ./venv/bin/activate Windows: venv/Scripts/activate Step 3: Install requiremenet packages To install requirement packages, just run this command in your terminal: Linux: python3 -m pip install -r requirements.txt Windows: python -m pip install -r requirements.txt","title":"Installation"},{"location":"installation/#step-1-create-a-virtual-environment","text":"First of all you need create a virtual environment to install packages in one place! For initialize a virtual environment run this command in your terminal: Linux: python3 -m venv venv Windows: python -m venv venv Note: Second venv is my choice, So you can choose another name.","title":"Step 1: Create a virtual environment"},{"location":"installation/#step-2-active-virtual-environment","text":"To active virtual environment, run this command in your terminal: Linux: source ./venv/bin/activate Windows: venv/Scripts/activate","title":"Step 2: Active virtual environment"},{"location":"installation/#step-3-install-requiremenet-packages","text":"To install requirement packages, just run this command in your terminal: Linux: python3 -m pip install -r requirements.txt Windows: python -m pip install -r requirements.txt","title":"Step 3: Install requiremenet packages"}]}